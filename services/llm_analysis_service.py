import re
import openai
import os
from functools import lru_cache

client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

@lru_cache(maxsize=500)
def analyze_trust_score_with_llm(profile: str) -> float:
    print("üßæ Token Profile (for LLM):\n", profile)

    prompt = f"""
–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç. –û—Ü–µ–Ω–∏ —Ä–∏—Å–∫ —Ç–æ–∫–µ–Ω–∞ –ø–æ —Å–ª–µ–¥—É—é—â–µ–º—É –ø—Ä–æ—Ñ–∏–ª—é:

{profile}

–û—Ç–≤–µ—Ç—å —Å—Ç—Ä–æ–≥–æ –æ–¥–Ω–∏–º —á–∏—Å–ª–æ–º –æ—Ç 0.0 (–º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∏—Å–∫) –¥–æ 1.0 (–Ω–∞–¥–µ–∂–Ω—ã–π —Ç–æ–∫–µ–Ω).
"""
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.0
    )
    text = response.choices[0].message.content
    match = re.search(r"\d\.\d+", text)
    return float(match.group()) if match else 0.0
